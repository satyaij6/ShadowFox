# ShadowFox Internship â€“ AI/ML Projects

This repository contains all completed projects from the **ShadowFox Artificial Intelligence & Machine Learning Internship**.
Each task demonstrates real-world machine learning workflow: dataset handling, preprocessing, model development, evaluation, and deployment-style execution.

---

## ğŸ“‚ Repository Structure

```
ShadowFox/
 â”œâ”€â”€ Task1 - CIFAR-10 Image Classification (Deep Learning)
 â”œâ”€â”€ Task2 - Car Selling Price Prediction (Machine Learning)
 â””â”€â”€ Task3 - Gemini Language Model Analysis (NLP & LLM Research)
```

---

## ğŸ§  Completed Projects

---

### ğŸ”¹ Task 1 â€” CIFAR-10 Image Classification (PyTorch)

A deep learning project that trains a custom CNN from scratch to classify images across **10 CIFAR-10 classes** such as airplane, automobile, cat, dog, and ship.

**Key Highlights**

* Custom CNN architecture written in PyTorch
* GPU-accelerated training
* Automatic dataset handling and preprocessing
* Inference script to classify single or batch images
* Model checkpoint saving + reproducible CLI interface

ğŸ“ˆ **Best Validation Accuracy:** *98%*
ğŸ“ Folder: `Task1/`

---

### ğŸ”¸ Task 2 â€” Car Selling Price Prediction (Regression Models)

A machine learning project that predicts a carâ€™s selling price using structured automotive data and engineered features such as mileage, fuel type, engine size, and years of service.

**Core Features**

* Data preprocessing, feature encoding, and transformation
* Multiple regression models trained and compared:

| Model             | Included |
| ----------------- | :------: |
| Linear Regression |     âœ”    |
| Ridge & Lasso     |     âœ”    |
| Decision Tree     |     âœ”    |
| Random Forest     |     âœ”    |
| Gradient Boosting |     âœ”    |

ğŸ“ˆ **Best Model:** Gradient Boosting
**RÂ² Score:** 0.9575
ğŸ“ Folder: `Task2/`

---

### ğŸ”¹ Task 3 â€” Gemini Language Model Analysis (NLP)

A research-focused project evaluating Googleâ€™s **Gemini language model** across multiple NLP dimensions including reasoning, domain adaptability, consistency, and prompt sensitivity.

**Analysis Includes**

* Multi-turn conversation evaluation
* Creativity and storytelling benchmarking
* Domain-wise LLM performance comparison
* Readability metrics, token analytics, and frequency mapping
* Statistical patterns (correlation, variability, consistency tests)

ğŸ“Š **Sample Results**

* Total responses analyzed: 13
* Average response length: 27.3 words
* Context understanding: **100% success rate**
* Consistency score: **High (CV < 0.1)**

ğŸ“ Folder: `Task3/`

---

## ğŸ§° Tools & Technologies

| Category            | Tools                                       |
| ------------------- | ------------------------------------------- |
| Programming         | Python                                      |
| ML/DL Frameworks    | PyTorch, Scikit-Learn                       |
| Data Handling       | Pandas, NumPy                               |
| Visualizations      | Matplotlib, Seaborn                         |
| NLP/LLM             | Google Generative AI (Gemini API), textstat |
| Execution Platforms | Jupyter Notebook, Python Scripts            |

---

## ğŸ“Œ Learning Outcomes

Throughout the internship, I gained experience in:

* ML workflows from raw data â†’ model deployment style inference
* Training deep learning models from scratch
* Feature engineering and choosing suitable ML models
* Evaluating models using industry-standard metrics
* Working with LLM inference, analysis frameworks, and API-driven NLP systems
* Structuring code, documenting results, and version-controlling projects with Git/GitHub

---

## ğŸ§¾ Proof of Work

Each task directory includes:

âœ” Source code
âœ” Requirements file
âœ” Project-specific README
âœ” Results (plots, metrics, or checkpoints)
---

## ğŸ¤ Acknowledgment

Completed as part of the **ShadowFox AI/ML Internship Program**.
All work is original and executed independently.
